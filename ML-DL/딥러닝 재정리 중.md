Neural network 에서 데이터가 hidden layer를 거쳐 정교한 예측을 가능하게함

![](https://images.velog.io/images/hangils/post/73c0e0b0-7046-4698-bdb5-d8eeab12d468/image.png)  


Loss function : 모델의 정확도 평가시 오차를 구하는 식  
![image](https://user-images.githubusercontent.com/74512114/144419665-88a91943-0cc7-4359-8440-7cd567c52b66.png)
(평균 제곱 오차법)

Activation function(활성 함수) :
히든 레이어에 추가되는 함수로 비선형적이고 복잡한 예측을 가능하게 한다
activation function으로 non-linearity 성질을 부여 한다
![image](https://user-images.githubusercontent.com/74512114/144420952-538e65a7-c789-4983-bcb9-bf6ee18926d3.png)  

ex)  
![image](https://user-images.githubusercontent.com/74512114/144420416-665f44e6-c3cc-4c30-83a9-680131aeba41.png)
 
![image](https://user-images.githubusercontent.com/74512114/144420456-6d88e5e1-e6a9-4842-a029-ca0ad4b866c8.png)



------------

### 관련 용어 재정리

![image](https://user-images.githubusercontent.com/74512114/148132942-0f34c609-89ae-4c10-a1d2-d392eca55b1b.png)


<br> 

Supervised learning : 컴퓨터에게 Label이 무엇인지 알려주면서 컴퓨터를 학습 시키는 방법, 지도학습에는 정확한 input 과 output이 존재한다.
 - Classification : 주어진 데이터를 정해진 카테고리에 따라 분류 (yolo v5)  
 - Regression : 데이터들의 Feature를 기준으로 연속된 값을 예측하는 문제(연속된 값 -> ex.그래프) 패턴이나 트랜드, 경향을 예측할 때 사용  

<br>   

 
Unsupervised learning : 정답을 알려주지 않고 데이터를 군집화 하여 미래를 예측하는 학습. 라벨링이 되어있지 않은 데이터로 부터 패턴이나 형태를 찾아야 한다. 지도 학습에서 적절한 Feature를 찾아내기 위한 전처리 방법으로 비지도 학습을 사용하기도 한다.

<br>

![image](https://user-images.githubusercontent.com/74512114/148132993-a34e09ea-44a1-4793-a367-6a30395732d0.png)


 
Reinforcement Learning(RL) : 행동 심리학에서 나온 이론으로 분류할 수 있는 데이터가 존재하는것도 아니고 데이터가 있다해도 정답이 따로 정해져 있지 않으며, 자신이 한 행동에 대해 보상(reward)을 받으며 학습하는 것 

<br>  

### 딥러닝 Pre-Training , Fine-Tuning , Transfer learning

<br>   

#### pre-training(선핵항습, 사전훈련, 전처리과정) 
Multi Layered Perceptron (MLP) 에서 Weight(가중치) 와 Bias(편향) 을 잘 초기화 시키는 방법이다. 이러한 Pre-training을 통해 효과적으로 Layer를 쌓아서 여러개의 hidden layer도 효율 적으로 훈련 시킬 수 있다.

<br>   

또한, 이는 unsuperviesd learnung(비지도 학습)이 가능하기 때문에(가중치와 편향 초기화가 끝나면 레이블 된 데이터로 supervised learingn 해야 한다 -> fine tuning) 레이블 되지 않은 큰 데이터를 넣어 훈련 시킬 수 있다는 점이 장점이다. 

<br> 

#### Fine-tuning   
기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)으로 변형하고, 이미 학습된 모델 Weights로 부터 학습을 업데이트하는 방법
- 모델의 파라미터를 미세하게 조정하는 행위(딥러닝에서 이미 존재하는 추가 데이터를 투입하여 파라미터를 업데이트 하는 것)   
파인튜닝은 정교한 파라미터 튜닝    

<br> 

#### Transfer-learning
데이터셋으로 학습한 가중치의 일부를 능력이 유사하거나 새로운 분야의 신경망에 복사한 후, 그 상태로 재학습을 수행하는 것   
ex) 동양인과 서양인을 구분하는 신경망을 구현하고자 할 때, 여자와 남자를 구분하는 신경망에서 이미지의 특징을 추출하는 부분에 대한 파라미터들을 가져와 나머지를 내 데이터로 학습시켜 완성도를 높이는 것   
- 학습된 모델을 기반으로 최종 출력층을 바꿔 학습하는 기법   
- 학습된 모델의 최종 출력층을 보유 중인 데이터에 대응하는 출력층으로 바꾸고,
- 교체한 출력층의 결합 파라미터(그릭고 앞 층의 결합 파라미터)를 소량의 데이터로 다시 학습
- 입력층에 가까운 부분의 결합 파라미터를 변화시키지 않음!
  
<br> 

#### bottleneck feature
![image](https://user-images.githubusercontent.com/74512114/148133011-5314e8c4-7671-412a-9443-0e885573127d.png)

✔ 가장 마지막 CNN 블록, 즉 Fully-connected layer(Affine layer 또는 Dense layer 라고도 부름) 직전의 CNN 블록 결과를 보틀넥 피쳐(Bottleneck Feature) 라고 부른다.


